{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Beer_dataset_EDA notebook in order to generate preprocessed training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the saved numpy arrays\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape :  (7279, 11)\n",
      "X_test.shape :  (1820, 11)\n",
      "y_train.shape :  (7279,)\n",
      "y_test.shape :  (1820,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape : \", X_train.shape)\n",
    "print(\"X_test.shape : \", X_test.shape)\n",
    "print(\"y_train.shape : \", y_train.shape)\n",
    "print(\"y_test.shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training different ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Baseline Regression model using Random forest regressor\n",
    "A baseline regression model is defined without any hyper-parameter tuning. I will then define three regression models and tune them such that their performance should be better than the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import xgboost as xgb\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  49.84730208626374\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_model.predict(X_test)\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some of the predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N1 = 270\n",
    "N2 = 290\n",
    "\n",
    "# Specify the values of blue bars (height)\n",
    "y_true_eff = y_test[N1:N2]\n",
    "# Specify the values of orange bars (height)\n",
    "y_pred_eff = y_pred[N1:N2]\n",
    "\n",
    "# Position of bars on x-axis\n",
    "ind = np.arange(N2 - N1)\n",
    "\n",
    "# Figure size\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "# Width of a bar \n",
    "width = 0.3       \n",
    "\n",
    "# Plotting\n",
    "plt.bar(ind, y_true_eff , width, label='y_test')\n",
    "plt.bar(ind + width, y_pred_eff, width, label='y_pred')\n",
    "\n",
    "plt.xlabel('Different instances')\n",
    "plt.ylabel('Efficiency')\n",
    "plt.title('Ground truth efficiency vs Predicted efficiency of beer')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([50, max(max(y_true_eff), max(y_pred_eff))+3])\n",
    "\n",
    "# Finding the best position for legends and putting it\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Random forest regression model to predict Efficiency scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-43.84382246, -51.89873342, -49.45695783, -44.81466184,\n",
       "       -50.71072839])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "scores = cross_val_score(forest_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\ML_omscs\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Grid search\n",
    "#                'max_depth': max_depth,\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state = 42, n_jobs = -1)\n",
    "folds = KFold(n_splits = 5, shuffle = False, random_state = 42)\n",
    "\n",
    "hyper_params = {'n_estimators': [200, 300],\n",
    "                'max_features': ['auto'],\n",
    "                'min_samples_split': [2, 5] ,\n",
    "                'min_samples_leaf': [1, 3, 5],\n",
    "                'bootstrap': [True] }\n",
    "\n",
    "model_cv = GridSearchCV(estimator = forest_model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'neg_mean_squared_error', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=False),\n",
       "             estimator=RandomForestRegressor(n_jobs=-1, random_state=42),\n",
       "             param_grid={'bootstrap': [True], 'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [200, 300]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results\n",
    "\n",
    "cv_results.drop(['mean_fit_time','std_fit_time','mean_score_time','std_score_time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-43.754766</td>\n",
       "      <td>-51.424813</td>\n",
       "      <td>-49.271409</td>\n",
       "      <td>-44.290630</td>\n",
       "      <td>-50.225748</td>\n",
       "      <td>-47.793473</td>\n",
       "      <td>3.158099</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.723710</td>\n",
       "      <td>-6.475626</td>\n",
       "      <td>-6.591933</td>\n",
       "      <td>-6.634831</td>\n",
       "      <td>-6.389608</td>\n",
       "      <td>-6.563142</td>\n",
       "      <td>0.117918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-43.780562</td>\n",
       "      <td>-51.179482</td>\n",
       "      <td>-49.040225</td>\n",
       "      <td>-44.306129</td>\n",
       "      <td>-50.069928</td>\n",
       "      <td>-47.675265</td>\n",
       "      <td>3.046206</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.693092</td>\n",
       "      <td>-6.416003</td>\n",
       "      <td>-6.505740</td>\n",
       "      <td>-6.582243</td>\n",
       "      <td>-6.352917</td>\n",
       "      <td>-6.509999</td>\n",
       "      <td>0.120225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-43.601730</td>\n",
       "      <td>-51.545968</td>\n",
       "      <td>-49.053133</td>\n",
       "      <td>-44.259376</td>\n",
       "      <td>-50.231381</td>\n",
       "      <td>-47.738317</td>\n",
       "      <td>3.214240</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.035689</td>\n",
       "      <td>-9.578729</td>\n",
       "      <td>-9.785570</td>\n",
       "      <td>-9.912133</td>\n",
       "      <td>-9.643091</td>\n",
       "      <td>-9.791042</td>\n",
       "      <td>0.168233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-43.573109</td>\n",
       "      <td>-51.298257</td>\n",
       "      <td>-48.658320</td>\n",
       "      <td>-44.224549</td>\n",
       "      <td>-50.156090</td>\n",
       "      <td>-47.582065</td>\n",
       "      <td>3.128535</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.988573</td>\n",
       "      <td>-9.540874</td>\n",
       "      <td>-9.755594</td>\n",
       "      <td>-9.856742</td>\n",
       "      <td>-9.593448</td>\n",
       "      <td>-9.747046</td>\n",
       "      <td>0.165252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.812996</td>\n",
       "      <td>-51.362481</td>\n",
       "      <td>-48.260889</td>\n",
       "      <td>-44.235734</td>\n",
       "      <td>-50.497102</td>\n",
       "      <td>-47.433841</td>\n",
       "      <td>3.378813</td>\n",
       "      <td>3</td>\n",
       "      <td>-16.595470</td>\n",
       "      <td>-15.689621</td>\n",
       "      <td>-15.968880</td>\n",
       "      <td>-16.057031</td>\n",
       "      <td>-15.862521</td>\n",
       "      <td>-16.034705</td>\n",
       "      <td>0.305947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.859813</td>\n",
       "      <td>-51.454458</td>\n",
       "      <td>-48.083086</td>\n",
       "      <td>-44.260181</td>\n",
       "      <td>-50.488886</td>\n",
       "      <td>-47.429285</td>\n",
       "      <td>3.373838</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.543954</td>\n",
       "      <td>-15.650263</td>\n",
       "      <td>-15.958253</td>\n",
       "      <td>-16.033438</td>\n",
       "      <td>-15.880497</td>\n",
       "      <td>-16.013281</td>\n",
       "      <td>0.294775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.812996</td>\n",
       "      <td>-51.362481</td>\n",
       "      <td>-48.260889</td>\n",
       "      <td>-44.235734</td>\n",
       "      <td>-50.497102</td>\n",
       "      <td>-47.433841</td>\n",
       "      <td>3.378813</td>\n",
       "      <td>3</td>\n",
       "      <td>-16.595470</td>\n",
       "      <td>-15.689621</td>\n",
       "      <td>-15.968880</td>\n",
       "      <td>-16.057031</td>\n",
       "      <td>-15.862521</td>\n",
       "      <td>-16.034705</td>\n",
       "      <td>0.305947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.859813</td>\n",
       "      <td>-51.454458</td>\n",
       "      <td>-48.083086</td>\n",
       "      <td>-44.260181</td>\n",
       "      <td>-50.488886</td>\n",
       "      <td>-47.429285</td>\n",
       "      <td>3.373838</td>\n",
       "      <td>2</td>\n",
       "      <td>-16.543954</td>\n",
       "      <td>-15.650263</td>\n",
       "      <td>-15.958253</td>\n",
       "      <td>-16.033438</td>\n",
       "      <td>-15.880497</td>\n",
       "      <td>-16.013281</td>\n",
       "      <td>0.294775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.921752</td>\n",
       "      <td>-51.622709</td>\n",
       "      <td>-48.373254</td>\n",
       "      <td>-44.516238</td>\n",
       "      <td>-50.747897</td>\n",
       "      <td>-47.636370</td>\n",
       "      <td>3.408176</td>\n",
       "      <td>9</td>\n",
       "      <td>-23.819003</td>\n",
       "      <td>-22.597655</td>\n",
       "      <td>-23.129435</td>\n",
       "      <td>-23.231922</td>\n",
       "      <td>-22.821792</td>\n",
       "      <td>-23.119962</td>\n",
       "      <td>0.415450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.944114</td>\n",
       "      <td>-51.612810</td>\n",
       "      <td>-48.293104</td>\n",
       "      <td>-44.481183</td>\n",
       "      <td>-50.734742</td>\n",
       "      <td>-47.613190</td>\n",
       "      <td>3.400384</td>\n",
       "      <td>7</td>\n",
       "      <td>-23.769134</td>\n",
       "      <td>-22.523206</td>\n",
       "      <td>-23.106310</td>\n",
       "      <td>-23.199205</td>\n",
       "      <td>-22.836354</td>\n",
       "      <td>-23.086842</td>\n",
       "      <td>0.414477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.921752</td>\n",
       "      <td>-51.622709</td>\n",
       "      <td>-48.373254</td>\n",
       "      <td>-44.516238</td>\n",
       "      <td>-50.747897</td>\n",
       "      <td>-47.636370</td>\n",
       "      <td>3.408176</td>\n",
       "      <td>8</td>\n",
       "      <td>-23.819003</td>\n",
       "      <td>-22.597655</td>\n",
       "      <td>-23.129435</td>\n",
       "      <td>-23.231922</td>\n",
       "      <td>-22.821792</td>\n",
       "      <td>-23.119962</td>\n",
       "      <td>0.415450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>-42.944114</td>\n",
       "      <td>-51.612810</td>\n",
       "      <td>-48.293104</td>\n",
       "      <td>-44.481183</td>\n",
       "      <td>-50.734742</td>\n",
       "      <td>-47.613190</td>\n",
       "      <td>3.400384</td>\n",
       "      <td>6</td>\n",
       "      <td>-23.769134</td>\n",
       "      <td>-22.523206</td>\n",
       "      <td>-23.106310</td>\n",
       "      <td>-23.199205</td>\n",
       "      <td>-22.836354</td>\n",
       "      <td>-23.086842</td>\n",
       "      <td>0.414477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_bootstrap param_max_features param_min_samples_leaf  \\\n",
       "0             True               auto                      1   \n",
       "1             True               auto                      1   \n",
       "2             True               auto                      1   \n",
       "3             True               auto                      1   \n",
       "4             True               auto                      3   \n",
       "5             True               auto                      3   \n",
       "6             True               auto                      3   \n",
       "7             True               auto                      3   \n",
       "8             True               auto                      5   \n",
       "9             True               auto                      5   \n",
       "10            True               auto                      5   \n",
       "11            True               auto                      5   \n",
       "\n",
       "   param_min_samples_split param_n_estimators  \\\n",
       "0                        2                200   \n",
       "1                        2                300   \n",
       "2                        5                200   \n",
       "3                        5                300   \n",
       "4                        2                200   \n",
       "5                        2                300   \n",
       "6                        5                200   \n",
       "7                        5                300   \n",
       "8                        2                200   \n",
       "9                        2                300   \n",
       "10                       5                200   \n",
       "11                       5                300   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'bootstrap': True, 'max_features': 'auto', 'm...         -43.754766   \n",
       "1   {'bootstrap': True, 'max_features': 'auto', 'm...         -43.780562   \n",
       "2   {'bootstrap': True, 'max_features': 'auto', 'm...         -43.601730   \n",
       "3   {'bootstrap': True, 'max_features': 'auto', 'm...         -43.573109   \n",
       "4   {'bootstrap': True, 'max_features': 'auto', 'm...         -42.812996   \n",
       "5   {'bootstrap': True, 'max_features': 'auto', 'm...         -42.859813   \n",
       "6   {'bootstrap': True, 'max_features': 'auto', 'm...         -42.812996   \n",
       "7   {'bootstrap': True, 'max_features': 'auto', 'm...         -42.859813   \n",
       "8   {'bootstrap': True, 'max_features': 'auto', 'm...         -42.921752   \n",
       "9   {'bootstrap': True, 'max_features': 'auto', 'm...         -42.944114   \n",
       "10  {'bootstrap': True, 'max_features': 'auto', 'm...         -42.921752   \n",
       "11  {'bootstrap': True, 'max_features': 'auto', 'm...         -42.944114   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -51.424813         -49.271409         -44.290630   \n",
       "1          -51.179482         -49.040225         -44.306129   \n",
       "2          -51.545968         -49.053133         -44.259376   \n",
       "3          -51.298257         -48.658320         -44.224549   \n",
       "4          -51.362481         -48.260889         -44.235734   \n",
       "5          -51.454458         -48.083086         -44.260181   \n",
       "6          -51.362481         -48.260889         -44.235734   \n",
       "7          -51.454458         -48.083086         -44.260181   \n",
       "8          -51.622709         -48.373254         -44.516238   \n",
       "9          -51.612810         -48.293104         -44.481183   \n",
       "10         -51.622709         -48.373254         -44.516238   \n",
       "11         -51.612810         -48.293104         -44.481183   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0          -50.225748       -47.793473        3.158099               12   \n",
       "1          -50.069928       -47.675265        3.046206               10   \n",
       "2          -50.231381       -47.738317        3.214240               11   \n",
       "3          -50.156090       -47.582065        3.128535                5   \n",
       "4          -50.497102       -47.433841        3.378813                3   \n",
       "5          -50.488886       -47.429285        3.373838                1   \n",
       "6          -50.497102       -47.433841        3.378813                3   \n",
       "7          -50.488886       -47.429285        3.373838                2   \n",
       "8          -50.747897       -47.636370        3.408176                9   \n",
       "9          -50.734742       -47.613190        3.400384                7   \n",
       "10         -50.747897       -47.636370        3.408176                8   \n",
       "11         -50.734742       -47.613190        3.400384                6   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            -6.723710           -6.475626           -6.591933   \n",
       "1            -6.693092           -6.416003           -6.505740   \n",
       "2           -10.035689           -9.578729           -9.785570   \n",
       "3            -9.988573           -9.540874           -9.755594   \n",
       "4           -16.595470          -15.689621          -15.968880   \n",
       "5           -16.543954          -15.650263          -15.958253   \n",
       "6           -16.595470          -15.689621          -15.968880   \n",
       "7           -16.543954          -15.650263          -15.958253   \n",
       "8           -23.819003          -22.597655          -23.129435   \n",
       "9           -23.769134          -22.523206          -23.106310   \n",
       "10          -23.819003          -22.597655          -23.129435   \n",
       "11          -23.769134          -22.523206          -23.106310   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            -6.634831           -6.389608         -6.563142         0.117918  \n",
       "1            -6.582243           -6.352917         -6.509999         0.120225  \n",
       "2            -9.912133           -9.643091         -9.791042         0.168233  \n",
       "3            -9.856742           -9.593448         -9.747046         0.165252  \n",
       "4           -16.057031          -15.862521        -16.034705         0.305947  \n",
       "5           -16.033438          -15.880497        -16.013281         0.294775  \n",
       "6           -16.057031          -15.862521        -16.034705         0.305947  \n",
       "7           -16.033438          -15.880497        -16.013281         0.294775  \n",
       "8           -23.231922          -22.821792        -23.119962         0.415450  \n",
       "9           -23.199205          -22.836354        -23.086842         0.414477  \n",
       "10          -23.231922          -22.821792        -23.119962         0.415450  \n",
       "11          -23.199205          -22.836354        -23.086842         0.414477  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters :  {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters : \", model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_randomforest = RandomForestRegressor(n_estimators = best['n_estimators'], min_samples_leaf = best['min_samples_leaf'], \n",
    "                                         min_samples_split = best['min_samples_split']\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=3, n_estimators=300)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_randomforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost algorithm for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\ML_omscs\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = xgb.XGBRegressor(random_state = 42, n_jobs = -1)\n",
    "folds = KFold(n_splits = 5, shuffle = False, random_state = 42)\n",
    "\n",
    "hyper_params = {'n_estimators': [1000, 1500],\n",
    "                'max_depth' : [1, 3, 5],\n",
    "                'eta': [0.1, 0.01] }\n",
    "\n",
    "model_cv_xgb = GridSearchCV(estimator = xgboost_model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'neg_mean_squared_error', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=False),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weigh...\n",
       "                                    n_estimators=100, n_jobs=-1,\n",
       "                                    num_parallel_tree=None, predictor=None,\n",
       "                                    random_state=42, reg_alpha=None,\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'eta': [0.1, 0.01], 'max_depth': [1, 3, 5],\n",
       "                         'n_estimators': [1000, 1500]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_eta</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.599552</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta': 0.1, 'max_depth': 1, 'n_estimators': 1...</td>\n",
       "      <td>-43.589074</td>\n",
       "      <td>-51.958595</td>\n",
       "      <td>-48.498660</td>\n",
       "      <td>-45.324729</td>\n",
       "      <td>-53.940260</td>\n",
       "      <td>-48.662264</td>\n",
       "      <td>3.889118</td>\n",
       "      <td>6</td>\n",
       "      <td>-45.543032</td>\n",
       "      <td>-43.650078</td>\n",
       "      <td>-45.150922</td>\n",
       "      <td>-45.315387</td>\n",
       "      <td>-43.352412</td>\n",
       "      <td>-44.602366</td>\n",
       "      <td>0.912513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.887948</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'eta': 0.1, 'max_depth': 1, 'n_estimators': 1...</td>\n",
       "      <td>-43.794797</td>\n",
       "      <td>-51.795324</td>\n",
       "      <td>-48.510265</td>\n",
       "      <td>-45.295575</td>\n",
       "      <td>-53.842939</td>\n",
       "      <td>-48.647780</td>\n",
       "      <td>3.786934</td>\n",
       "      <td>5</td>\n",
       "      <td>-44.925365</td>\n",
       "      <td>-43.077316</td>\n",
       "      <td>-44.570863</td>\n",
       "      <td>-44.740414</td>\n",
       "      <td>-42.795029</td>\n",
       "      <td>-44.021797</td>\n",
       "      <td>0.897922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.323917</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta': 0.1, 'max_depth': 3, 'n_estimators': 1...</td>\n",
       "      <td>-46.627554</td>\n",
       "      <td>-52.183281</td>\n",
       "      <td>-51.708432</td>\n",
       "      <td>-46.048479</td>\n",
       "      <td>-53.495339</td>\n",
       "      <td>-50.012617</td>\n",
       "      <td>3.062351</td>\n",
       "      <td>8</td>\n",
       "      <td>-23.016547</td>\n",
       "      <td>-22.178156</td>\n",
       "      <td>-22.357129</td>\n",
       "      <td>-22.238310</td>\n",
       "      <td>-22.710342</td>\n",
       "      <td>-22.500097</td>\n",
       "      <td>0.317346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.952797</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'eta': 0.1, 'max_depth': 3, 'n_estimators': 1...</td>\n",
       "      <td>-47.743027</td>\n",
       "      <td>-53.416793</td>\n",
       "      <td>-52.931155</td>\n",
       "      <td>-47.062037</td>\n",
       "      <td>-54.434608</td>\n",
       "      <td>-51.117524</td>\n",
       "      <td>3.079388</td>\n",
       "      <td>10</td>\n",
       "      <td>-18.422633</td>\n",
       "      <td>-17.895853</td>\n",
       "      <td>-18.195475</td>\n",
       "      <td>-17.927212</td>\n",
       "      <td>-18.239915</td>\n",
       "      <td>-18.136218</td>\n",
       "      <td>0.198875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.198665</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta': 0.1, 'max_depth': 5, 'n_estimators': 1...</td>\n",
       "      <td>-47.057704</td>\n",
       "      <td>-55.535752</td>\n",
       "      <td>-54.646940</td>\n",
       "      <td>-47.705377</td>\n",
       "      <td>-53.541717</td>\n",
       "      <td>-51.697498</td>\n",
       "      <td>3.586008</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.287969</td>\n",
       "      <td>-6.168110</td>\n",
       "      <td>-6.084225</td>\n",
       "      <td>-5.671240</td>\n",
       "      <td>-5.944606</td>\n",
       "      <td>-6.031230</td>\n",
       "      <td>0.211923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.404759</td>\n",
       "      <td>0.117728</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'eta': 0.1, 'max_depth': 5, 'n_estimators': 1...</td>\n",
       "      <td>-47.786847</td>\n",
       "      <td>-56.835154</td>\n",
       "      <td>-56.204671</td>\n",
       "      <td>-48.780885</td>\n",
       "      <td>-54.630165</td>\n",
       "      <td>-52.847545</td>\n",
       "      <td>3.807819</td>\n",
       "      <td>12</td>\n",
       "      <td>-3.107706</td>\n",
       "      <td>-3.029765</td>\n",
       "      <td>-3.014445</td>\n",
       "      <td>-2.826091</td>\n",
       "      <td>-2.943844</td>\n",
       "      <td>-2.984370</td>\n",
       "      <td>0.094733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.585721</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta': 0.01, 'max_depth': 1, 'n_estimators': ...</td>\n",
       "      <td>-43.645272</td>\n",
       "      <td>-54.109271</td>\n",
       "      <td>-50.240200</td>\n",
       "      <td>-47.058103</td>\n",
       "      <td>-55.412710</td>\n",
       "      <td>-50.093111</td>\n",
       "      <td>4.364292</td>\n",
       "      <td>9</td>\n",
       "      <td>-50.044062</td>\n",
       "      <td>-47.751182</td>\n",
       "      <td>-48.920965</td>\n",
       "      <td>-49.304534</td>\n",
       "      <td>-47.300427</td>\n",
       "      <td>-48.664234</td>\n",
       "      <td>1.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.893726</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'eta': 0.01, 'max_depth': 1, 'n_estimators': ...</td>\n",
       "      <td>-43.520303</td>\n",
       "      <td>-53.502546</td>\n",
       "      <td>-49.531923</td>\n",
       "      <td>-46.607665</td>\n",
       "      <td>-55.114582</td>\n",
       "      <td>-49.655404</td>\n",
       "      <td>4.278938</td>\n",
       "      <td>7</td>\n",
       "      <td>-49.155443</td>\n",
       "      <td>-46.930627</td>\n",
       "      <td>-48.159944</td>\n",
       "      <td>-48.468844</td>\n",
       "      <td>-46.449624</td>\n",
       "      <td>-47.832896</td>\n",
       "      <td>0.998805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.315519</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta': 0.01, 'max_depth': 3, 'n_estimators': ...</td>\n",
       "      <td>-43.852360</td>\n",
       "      <td>-51.320495</td>\n",
       "      <td>-47.927969</td>\n",
       "      <td>-44.681029</td>\n",
       "      <td>-52.706119</td>\n",
       "      <td>-48.097594</td>\n",
       "      <td>3.502836</td>\n",
       "      <td>3</td>\n",
       "      <td>-40.616066</td>\n",
       "      <td>-38.740596</td>\n",
       "      <td>-40.436280</td>\n",
       "      <td>-40.432322</td>\n",
       "      <td>-38.746607</td>\n",
       "      <td>-39.794374</td>\n",
       "      <td>0.860519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.934267</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.012493</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'eta': 0.01, 'max_depth': 3, 'n_estimators': ...</td>\n",
       "      <td>-44.295449</td>\n",
       "      <td>-50.943631</td>\n",
       "      <td>-47.762161</td>\n",
       "      <td>-44.460444</td>\n",
       "      <td>-52.315262</td>\n",
       "      <td>-47.955389</td>\n",
       "      <td>3.273690</td>\n",
       "      <td>1</td>\n",
       "      <td>-38.783611</td>\n",
       "      <td>-36.849377</td>\n",
       "      <td>-38.455342</td>\n",
       "      <td>-38.471192</td>\n",
       "      <td>-37.067195</td>\n",
       "      <td>-37.925343</td>\n",
       "      <td>0.801198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.147178</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta': 0.01, 'max_depth': 5, 'n_estimators': ...</td>\n",
       "      <td>-44.044705</td>\n",
       "      <td>-50.937189</td>\n",
       "      <td>-48.820468</td>\n",
       "      <td>-44.511466</td>\n",
       "      <td>-51.657336</td>\n",
       "      <td>-47.994233</td>\n",
       "      <td>3.177748</td>\n",
       "      <td>2</td>\n",
       "      <td>-32.222100</td>\n",
       "      <td>-31.405848</td>\n",
       "      <td>-31.599214</td>\n",
       "      <td>-31.621626</td>\n",
       "      <td>-30.672586</td>\n",
       "      <td>-31.504275</td>\n",
       "      <td>0.497886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.211681</td>\n",
       "      <td>0.038951</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'eta': 0.01, 'max_depth': 5, 'n_estimators': ...</td>\n",
       "      <td>-44.361003</td>\n",
       "      <td>-50.809708</td>\n",
       "      <td>-49.555856</td>\n",
       "      <td>-44.548202</td>\n",
       "      <td>-51.494785</td>\n",
       "      <td>-48.153911</td>\n",
       "      <td>3.084394</td>\n",
       "      <td>4</td>\n",
       "      <td>-28.839904</td>\n",
       "      <td>-28.152529</td>\n",
       "      <td>-28.353588</td>\n",
       "      <td>-27.812729</td>\n",
       "      <td>-27.895638</td>\n",
       "      <td>-28.210878</td>\n",
       "      <td>0.368061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_eta  \\\n",
       "0        0.599552      0.018967         0.001753        0.002182       0.1   \n",
       "1        0.887948      0.022673         0.006250        0.007654       0.1   \n",
       "2        1.323917      0.006142         0.003125        0.006250       0.1   \n",
       "3        1.952797      0.015309         0.009375        0.007654       0.1   \n",
       "4        2.198665      0.014071         0.015626        0.000002       0.1   \n",
       "5        3.404759      0.117728         0.012374        0.006192       0.1   \n",
       "6        0.585721      0.019928         0.006250        0.007655      0.01   \n",
       "7        0.893726      0.018221         0.009374        0.007654      0.01   \n",
       "8        1.315519      0.011780         0.003125        0.006249      0.01   \n",
       "9        1.934267      0.007565         0.012493        0.006247      0.01   \n",
       "10       2.147178      0.018667         0.012499        0.006249      0.01   \n",
       "11       3.211681      0.038951         0.015623        0.000001      0.01   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0                1               1000   \n",
       "1                1               1500   \n",
       "2                3               1000   \n",
       "3                3               1500   \n",
       "4                5               1000   \n",
       "5                5               1500   \n",
       "6                1               1000   \n",
       "7                1               1500   \n",
       "8                3               1000   \n",
       "9                3               1500   \n",
       "10               5               1000   \n",
       "11               5               1500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'eta': 0.1, 'max_depth': 1, 'n_estimators': 1...         -43.589074   \n",
       "1   {'eta': 0.1, 'max_depth': 1, 'n_estimators': 1...         -43.794797   \n",
       "2   {'eta': 0.1, 'max_depth': 3, 'n_estimators': 1...         -46.627554   \n",
       "3   {'eta': 0.1, 'max_depth': 3, 'n_estimators': 1...         -47.743027   \n",
       "4   {'eta': 0.1, 'max_depth': 5, 'n_estimators': 1...         -47.057704   \n",
       "5   {'eta': 0.1, 'max_depth': 5, 'n_estimators': 1...         -47.786847   \n",
       "6   {'eta': 0.01, 'max_depth': 1, 'n_estimators': ...         -43.645272   \n",
       "7   {'eta': 0.01, 'max_depth': 1, 'n_estimators': ...         -43.520303   \n",
       "8   {'eta': 0.01, 'max_depth': 3, 'n_estimators': ...         -43.852360   \n",
       "9   {'eta': 0.01, 'max_depth': 3, 'n_estimators': ...         -44.295449   \n",
       "10  {'eta': 0.01, 'max_depth': 5, 'n_estimators': ...         -44.044705   \n",
       "11  {'eta': 0.01, 'max_depth': 5, 'n_estimators': ...         -44.361003   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -51.958595         -48.498660         -45.324729   \n",
       "1          -51.795324         -48.510265         -45.295575   \n",
       "2          -52.183281         -51.708432         -46.048479   \n",
       "3          -53.416793         -52.931155         -47.062037   \n",
       "4          -55.535752         -54.646940         -47.705377   \n",
       "5          -56.835154         -56.204671         -48.780885   \n",
       "6          -54.109271         -50.240200         -47.058103   \n",
       "7          -53.502546         -49.531923         -46.607665   \n",
       "8          -51.320495         -47.927969         -44.681029   \n",
       "9          -50.943631         -47.762161         -44.460444   \n",
       "10         -50.937189         -48.820468         -44.511466   \n",
       "11         -50.809708         -49.555856         -44.548202   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0          -53.940260       -48.662264        3.889118                6   \n",
       "1          -53.842939       -48.647780        3.786934                5   \n",
       "2          -53.495339       -50.012617        3.062351                8   \n",
       "3          -54.434608       -51.117524        3.079388               10   \n",
       "4          -53.541717       -51.697498        3.586008               11   \n",
       "5          -54.630165       -52.847545        3.807819               12   \n",
       "6          -55.412710       -50.093111        4.364292                9   \n",
       "7          -55.114582       -49.655404        4.278938                7   \n",
       "8          -52.706119       -48.097594        3.502836                3   \n",
       "9          -52.315262       -47.955389        3.273690                1   \n",
       "10         -51.657336       -47.994233        3.177748                2   \n",
       "11         -51.494785       -48.153911        3.084394                4   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0           -45.543032          -43.650078          -45.150922   \n",
       "1           -44.925365          -43.077316          -44.570863   \n",
       "2           -23.016547          -22.178156          -22.357129   \n",
       "3           -18.422633          -17.895853          -18.195475   \n",
       "4            -6.287969           -6.168110           -6.084225   \n",
       "5            -3.107706           -3.029765           -3.014445   \n",
       "6           -50.044062          -47.751182          -48.920965   \n",
       "7           -49.155443          -46.930627          -48.159944   \n",
       "8           -40.616066          -38.740596          -40.436280   \n",
       "9           -38.783611          -36.849377          -38.455342   \n",
       "10          -32.222100          -31.405848          -31.599214   \n",
       "11          -28.839904          -28.152529          -28.353588   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0           -45.315387          -43.352412        -44.602366         0.912513  \n",
       "1           -44.740414          -42.795029        -44.021797         0.897922  \n",
       "2           -22.238310          -22.710342        -22.500097         0.317346  \n",
       "3           -17.927212          -18.239915        -18.136218         0.198875  \n",
       "4            -5.671240           -5.944606         -6.031230         0.211923  \n",
       "5            -2.826091           -2.943844         -2.984370         0.094733  \n",
       "6           -49.304534          -47.300427        -48.664234         1.007319  \n",
       "7           -48.468844          -46.449624        -47.832896         0.998805  \n",
       "8           -40.432322          -38.746607        -39.794374         0.860519  \n",
       "9           -38.471192          -37.067195        -37.925343         0.801198  \n",
       "10          -31.621626          -30.672586        -31.504275         0.497886  \n",
       "11          -27.812729          -27.895638        -28.210878         0.368061  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_xgb = pd.DataFrame(model_cv_xgb.cv_results_)\n",
    "cv_results_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.01, 'max_depth': 3, 'n_estimators': 1500}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = model_cv_xgb.best_params_\n",
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters :  {'eta': 0.01, 'max_depth': 3, 'n_estimators': 1500}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters : \", model_cv_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost = xgb.XGBRegressor(n_estimators = best_xgb['n_estimators'], eta = best_xgb['eta'], \n",
    "                                         max_depth = best_xgb['max_depth']\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             eta=0.01, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.00999999978,\n",
       "             max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1500, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Linear Regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression(n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_randomforest\n",
    "\n",
    "best_xgboost\n",
    "\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance on unseen test data: Evaluation of the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model error on test data : \n",
      "MSE:  48.17650176666321\n"
     ]
    }
   ],
   "source": [
    "y_pred_RF = best_randomforest.predict(X_test)\n",
    "print(\"Random forest model error on test data : \")\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model error on test data : \n",
      "MSE:  48.79954799096252\n"
     ]
    }
   ],
   "source": [
    "y_pred_XG = best_xgboost.predict(X_test)\n",
    "print(\"XGBoost model error on test data : \")\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred_XG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model error on test data : \n",
      "MSE:  55.03999697878123\n"
     ]
    }
   ],
   "source": [
    "y_pred_LR = lr_model.predict(X_test)\n",
    "print(\"Linear regression model error on test data : \")\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAG5CAYAAADiXxGlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm/UlEQVR4nO3debhddX3v8fcnJBIgSmUSFCTARcYg0BBAuCoidYCiVq2AWnAoWhxKvVVjr1qHaunFqzhWsQ4ghaKoFXECI4HCpcWgIFCgDCJEKYQoMsgYvvePtYKbQ5Kzz7DPsPJ+Pc9+9l7zdw9nf85a67d/K1WFJEldMWOyC5AkaTwZbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNU1KSuUkqycwJ3GaSfCnJb5JcPKBtHJXkgkGse6SGvsZJvpfkyJ7pf5fk9iT/3Q6/JMnNSe5Ossdk1T0ZktyY5Ll9zDfhn1s9lsG2Fmn/OB9IssmQ8Ze2f4xz2+Etk3y9/VL7bZLLkxzVTlv5h3v3kNsrJv4Zjbv9gYOALatqwVhXNt2+5KrqBVV1EkCSrYD/BexcVZu3s3wEeHNVzamqn05kbUkWJ3n9RG5T09e0+IPTuPo5cDjwSYAk84D1hszzFeAyYGvgfmAesPmQef6gqh4abKkTbmvgxqq6Z6QLJpk53q9HkgCpqofHc7192hpYXlW3DRl35WhWNojXR1od99jWPl8B/qxn+Ejg5CHz7AV8uaruqaqHquqnVfW9kW4oyWFJlgwZ91dJzmwfH5zkp0nubA9xvW8N63rUoaAk70tySs/wPkn+X5I7klyW5Nk9045KckOSu5L8PMkrV7H+1wH/BOzb7oG+vx3/50muS/LrJGcmeXLPMpXkTUmuBa5dRdnnt/d3tOvct2fZj7SHPH+e5AU94xcn+VCSC4HfAdsm2THJOW0N1yT50575123XdVOSW5N8NsnQf1RWzrtOO+/tSW4ADh4yfXGS17ev8znAk9u6T0tyN7AOcFmS69v5n9zu2S9rn8dbh7w/ZyQ5JcmdwFFJNkzyhSS3JPlle6hznZ736IJVvS5JPgT8T+BTbT2fWsVzW7l3/Jr2s/SbJG9MsleSn7Wfi0/1zD8jybuT/CLJbUlOTrJhz/RXt9OWJ/nfQ7Y1I8nCJNe307+aZKPVvObDfvY0AFXlbS25ATcCzwWuAXai+aK6meY/8QLmtvP9ELgQOAx46pB1zG3nndnH9tYH7gK27xn3Y+Cw9vGzafYGZwC7AbcCL17VdlbW3rOe9wGntI+fAiwHXtiu66B2eFNgA+BOYId23i2AXVZT71HABT3DzwFuB/YE1qXZyz2/Z3rRBMBGwHqrWN9jXqt2Gw8Cf96+/n8B/IpmzwxgMXATsAvNEZUN2/foNe3wnm1Nu7TznwCc2dbweODbwN+v5vm9Ebga2Kqd/9whr/Fi4PU9783SIcsX8D/axzOAS4D3Ao8DtgVuAJ7X8/48CLy4nXc94F+Bz7XvyWbAxcAbRvC6vH4Nn7WVr/VngdnAHwH3tdvcjOYzchvwrHb+1wLXtXXPAb4BfKWdtjNwN/DM9n3/KPAQ7ecPOBb4d2DLdvrngNOGvueM4LPnbZy/6ya7AG8T+Gb/PtjeDfw98HyaL+aZPDrYnggcR3PYaQVwKbBXO23lH+4dQ247rWabpwDvbR9vTxN0669m3hOAjw3ZTj/B9s6VX0o9039Asze6QVvfS1lF+AxZ5igeHWxfAP5Pz/Acmi/fla9TAc9Zw/oe9Rx6tnFdz/D67Tybt8OLgQ/0TH8F8G9D1vs54G+BAPcA2/VM2xf4+Wrq+RHwxp7hP2L0wbY3cNOQ6e8CvtTz/vT+E/AkmsPa6/WMOxw4dwSvSz/B9pSeccuBV/QMfx04tn28CDimZ9oO7Xs7kyas/6Vn2gbAA/w+2K4CDuyZvkXPso+854zgs+dtfG8eilw7fQU4gubLZOhhSKrqN1W1sKp2oflCuhT41yTpmW2TqvqDnttVq9nWqTRfYLTb/Neq+h1Akr2TnNseyvotzR7FJqtZz5psDby8Pdx0R5I7aBqCbFHN+bJXtOu+Jcl3kuzY53qfDPxi5UBV3U3zZfmUnnluHkW9/92zzt+1D+esZp1bA3sPeW6vpDnnuSlNAFzSM+377fjVPZ/edf9iNfP1Y2uaQ5W9df0Nzedldc9jFs17sHL+z9HsTa003OvSj1t7Ht+7iuGV63vUe9s+ntnW/6jXqf0MLR/yXL7Z8zyuovkHsPe5M8bPnsbAYFsLVdUvaBqRvJDmEMya5r2dpjXck2kOX43U2cAmSXanCbhTe6adSnMYbauq2pDmMFIes4bGPTRf4iv1Nma5mWaPrTdoN6iq49rn8IOqOojmP+urgc/3WfuvaL7EAEiyAbAx8MueedZ0eYzRXjqjd7mbgfOGPLc5VfUXNIck76U5vLVy2oZVtbowuIXmMORKTx1lfSvr+vmQuh5fVS9cw/O4n0f/Q/SE9p+nfoz3ZUge9d7SvBYP0QTho16nJOvTvO8r3Qy8YMhzn11VvZ+LpujRf/Y0Bgbb2ut1NIfRHtMCMMk/JNk1ycwkj6c533FdVS1/zFqGUU1LuDOA42mC8ZyeyY8Hfl1V9yVZQLNHtzqXAoclmZVkPvCynmmnAH+c5HltA4nZSZ6d5mcLT0pyaBtK99OcO1nRZ/mnAq9JsnuSdYEPA/9RVTf2ufwy4GGa8zijdRbwtLYxw6z2tleSnappLfl54GNJNgNI8pQkz1vNur4KvLV9XZ4ILBxDXRcDdyZ5Z5L12td91yR7rWrmqrqF5p+c/5vkCW0DjO2SPKvP7d3K2F7HoU4D/irJNknm0Ly3p/d8Xg9Jsn+SxwEf4NHflZ8FPpRka4AkmyZ50dANjPGzpzEw2NZSVXV9VS1ZzeT1gW/SnB+4geY/20OHzLOypd/K29vWsLlTac7tfa0e3eT7GOADSe6iOa/x1TWs4z3AdsBvgPfTs+dXVTcDL6I5FLaM5j/qt9N8vmfQ/B7rV8CvgWe12x1WVS1qt/t1mv/it6NpUNOX9nDah4AL28NW+/S7bM867qI5F3YYzXP4b+AfaBotQHN+8Trg39O0PvwhzfmiVfk8zbnHy4CfMMze+jB1rQD+GNidZu//dppWpRuuYbE/o2lo8p807+MZNHsy/fg48LK2teMnRll2ry/SHJI/n6b++4C3AFTVlcCbaD5jt7S1Lh1Sy5nA2e1n999pzjkONerPnsZmZYsjSZI6wT02SVKnGGySpE4x2CRJnWKwSZI6ZVp0grzJJpvU3LlzJ7sMSdIUcskll9xeVY/pkGBaBNvcuXNZsmR1LdMlSWujJKvsPcdDkZKkTjHYJEmdYrBJkjplWpxjW5UHH3yQpUuXct999012KdPO7Nmz2XLLLZk1a9ZklyJJ427aBtvSpUt5/OMfz9y5c3n01VS0JlXF8uXLWbp0Kdtss81klyNJ427aHoq877772HjjjQ21EUrCxhtv7J6upM6atsEGGGqj5OsmqcumdbBJkjTUtD3HNtTchd8Z1/XdeNzB47o+SdLEcI9tGvra177GTjvtxAEHHDDZpUjSlNOZPba1QVVRVXzhC1/gM5/5jMEmSavgHtsY3Hjjjey44468/vWvZ9ddd+WVr3wlP/zhD9lvv/3YfvvtufjiiznvvPPYfffd2X333dljjz246667ADj++OPZa6+92G233fjbv/3bNW5jp5124phjjmHPPffkgx/8IBdccAFvfOMbefvb3z5RT1WSpg332Mbouuuu42tf+xonnngie+21F6eeeioXXHABZ555Jh/+8IdZsWIFn/70p9lvv/24++67mT17NmeffTbXXnstF198MVXFoYceyvnnn88zn/nMVW7jmmuu4Utf+hKf+cxnADj33HP5yEc+wvz58yfyqUrStOAe2xhts802zJs3jxkzZrDLLrtw4IEHkoR58+Zx4403st9++/G2t72NT3ziE9xxxx3MnDmTs88+m7PPPps99tiDPffck6uvvpprr712tdvYeuut2WeffSbwWUnS9OUe2xitu+66jzyeMWPGI8MzZszgoYceYuHChRx88MF897vfZZ999uGHP/whVcW73vUu3vCGN/S1jQ022GAgtUtSF3Um2KZq8/zrr7+eefPmMW/ePC666CKuvvpqnve85/Ge97yHV77ylcyZM4df/vKXzJo1i80222yyy5Wkaa8zwTZVnXDCCZx77rmss8467LzzzrzgBS9g3XXX5aqrrmLfffcFYM6cOZxyyikGm6S+zTtp3mSXMGqXH3n5QNefqhroBsbD/Pnza+gVtK+66ip22mmnSapo+vP1k6Y3gw2SXFJVj2lFZ+MRSVKneChyili+fDkHHnjgY8YvWrSIjTfeeBIqkqTpyWCbIjbeeGMuvfTSyS5DkqY9D0VKkjrFYJMkdYrBJknqlO6cY3vfhuO8vt+O7/okSRPCPbYOmjt3LrfffvtklyFJk8JgkyR1isE2BhNxPbYf//jH7Lbbbtx3333cc8897LLLLlxxxRU8/PDDHHPMMeyyyy4ccsghvPCFL+SMM854ZLnjjz+eBQsWsGDBAq677rqBvxaSNFV05xzbJBn09dj22msvDj30UN797ndz77338qpXvYpdd92VM844gxtvvJHLL7+c2267jZ122onXvva1jyz3hCc8gYsvvpiTTz6ZY489lrPOOmsiXxZJmjTusY3RRFyP7b3vfS/nnHMOS5Ys4R3veAcAF1xwAS9/+cuZMWMGm2++OQcccMCjljn88MMfub/ooosG9wJI0hTjHtsYTcT12H79619z99138+CDD3LfffexwQYbMFzn1UlW+ViSuq47wTZFm+ePx/XYjj76aD74wQ/y85//nHe+85186lOfYv/99+ekk07iyCOPZNmyZSxevJgjjjjikWVOP/10Fi5cyOmnn/7I5XEkaW3QnWCbosZ6PbaTTz6ZmTNncsQRR7BixQqe8Yxn8KMf/YiXvvSlLFq0iF133ZWnPe1p7L333my44e9/y3f//fez99578/DDD3PaaadN2POVpMnm9dimsbvvvps5c+awfPlyFixYwIUXXsjmm2/e17K+ftL05vXYVn89NvfYprFDDjmEO+64gwceeID3vOc9fYeaJHWZwTZFjOZ6bIsXLx5wVZI0/RhsU4TXY5Ok8eHv2CRJnWKwSZI6xWCTJHVKZ86xjXfT1/FqjipJmljusU0Dc+bMmewSJGnaMNimqRUrVkx2CZI0JRlsYzAR12PrtXjxYg444ACOOOII5s2bvr0OSNIgdeYc22QZ9PXYhrr44ou54oor2GabbSbg2UnS9OMe2xhNxPXYei1YsMBQk6Q1cI9tjCbiemy9Nthgg3GrXZK6aKDBluRG4C5gBfBQVc1PshFwOjAXuBH406r6zVi3NVWb54/H9dgkSf2biD22A6rq9p7hhcCiqjouycJ2+J0TUMekGOv12CRJIzPQ67G1e2zze4MtyTXAs6vqliRbAIuraoc1rcfrsY0/Xz9pevN6bKu/HtugG48UcHaSS5Ic3Y57UlXdAtDer3I3JcnRSZYkWbJs2bIBlylJ6opBH4rcr6p+lWQz4JwkV/e7YFWdCJwIzR7boAqcKkZzPTZJ0mMNNNiq6lft/W1JvgksAG5NskXPocjbxrB+koxTtZNrIq/HNsjDz5I02QZ2KDLJBkkev/Ix8EfAFcCZwJHtbEcC3xrN+mfPns3y5cv9kh6hqmL58uXMnj17skuRpIEY5B7bk4BvtntUM4FTq+r7SX4MfDXJ64CbgJePZuVbbrklS5cuxfNvIzd79my23HLLyS5DkgZiYMFWVTcAT1/F+OXAY08mjdCsWbPsgUOS9Bh2qSVJ6hS71JLG2/s2nOwKRud9v53sCqRx4R6bJKlTDDZJUqcYbJKkTjHYJEmdslY1Hpm78DuTXcKo3HjcwZNdgiRNG+6xSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6ZeDBlmSdJD9NclY7vFGSc5Jc294/cdA1SJLWHhOxx/aXwFU9wwuBRVW1PbCoHZYkaVwMNNiSbAkcDPxTz+gXASe1j08CXjzIGiRJa5dB77GdALwDeLhn3JOq6haA9n6zVS2Y5OgkS5IsWbZs2YDLlCR1xcCCLckhwG1Vdclolq+qE6tqflXN33TTTce5OklSV80c4Lr3Aw5N8kJgNvCEJKcAtybZoqpuSbIFcNsAa5AkrWUGtsdWVe+qqi2rai5wGPCjqnoVcCZwZDvbkcC3BlWDJGntMxm/YzsOOCjJtcBB7bAkSeNikIciH1FVi4HF7ePlwIETsV1J0trHnkckSZ1isEmSOsVgkyR1isEmSeqUvhqPJNmM5ndpTwbuBa4AllTVw2tcUJKkCbbGYEtyAE0nxRsBP6X5MfVsmv4dt0tyBvB/q+rOAdcpSVJfhttjeyHw51V109AJSWYCh9D8Fu3rA6hNkqQRW2OwVdXbk8xI8qdV9dUh0x4C/nWQxUmSNFLDNh5pz6O9ZQJqkSRpzPptFXl2kr9OslV7BeyNkmw00MokSRqFfrvUem17/6aecQVsO77lSJI0Nn0FW1VtM+hCJEkaD30dikyyfpJ3JzmxHd6+vZCoJElTSr/n2L4EPAA8ox1eCvzdQCqSJGkM+g227arq/wAPAlTVvUAGVpUkSaPUb7A9kGQ9mgYjJNkOuH9gVUmSNEr9top8H/B9YKsk/0zTb+RrBlWUJEmj1W+ryLOTXALsQ3MI8i+r6vaBViZJ0ij02ypyUVUtr6rvVNVZVXV7kkWDLk6SpJEarnf/2cD6wCZJnsjvG4w8geYSNpIkTSnDHYp8A3AsTYhdwu+D7U7g04MrS5Kk0Rmud/+PAx9P8taq+kTvtCTrDrQySZJGod/m/ketYtxF41iHJEnjYrhzbJsDTwHWS7IHjz7Htv6Aa5MkacSGO8f2PJq9tS2Bj/aMvxP4mwHVJEnSqA13ju0k4KQkL62qr09QTZIkjVq/59guTPKFJN8DSLJzktcNsC5JkkZlJL37/4Df/3btv2h+BiBJ0pTSb7BtUlVfBR4GqKqHgBUDq0qSpFHqN9juSbIxv+/dfx/gtwOrSpKkUeq3d/+3AWcC2yW5ENgUeNnAqpIkaZT67d3/J0meBexA81u2a6rqwYFWJknSKPQVbG1nyMcA+9Mcjvy3JJ+tqvsGWZwkSSPV76HIk4G7gE+2w4cDXwFePoiiJEkarX6DbYeqenrP8LlJLhtEQZIkjUW/rSJ/2raEBCDJ3sCFgylJkqTRG64T5MtpzqnNAv4syU3t8NbAfw6+PEmSRma4Q5GHTEgVkiSNk+E6Qf7FRBUiSdJ46PccmyRJ04LBJknqlL6CLckGSWa0j5+W5NAkswZbmiRJI9fvHtv5wOwkTwEWAa8BvjyooiRJGq1+gy1V9TvgT4BPVtVLgJ0HV5YkSaPTd7Al2Rd4JfCddly/vZZIkjRh+g22Y4F3Ad+sqiuTbAucO7CqJEkapX4vW3MecF7P8A3AWwdVlCRJozVcl1onVNWxSb5Ne/XsXlV16MAqkyRpFIbbY/tKe/+RQRciSdJ4GK5LrUva+/PWNJ8kSVOFPY9IkjrFYJMkdcqwwZZknSTHT0QxkiSN1bDBVlUrgD9MkgmoR5KkMem395CfAt9K8jXgnpUjq+obA6lKkqRR6jfYNgKWA8/pGVeAwSZJmlL67XnkNYMuRJKk8dDv9dielmRRkiva4d2SvHuYZWYnuTjJZUmuTPL+dvxGSc5Jcm17/8SxPw1Jkhr9Nvf/PE0nyA8CVNXPgMOGWeZ+4DlV9XRgd+D5SfYBFgKLqmp7mmu7LRxF3ZIkrVK/wbZ+VV08ZNxDa1qgGne3g7PaWwEvAk5qx58EvLjPGiRJGla/wXZ7ku1oO0JO8jLgluEWan8DdylwG3BOVf0H8KSqugWgvd9sNcsenWRJkiXLli3rs0xJ0tqu32B7E/A5YMckv6S5Ptsbh1uoqlZU1e7AlsCCJLv2W1hVnVhV86tq/qabbtrvYpKktVy/rSJvAJ6bZANgRlXdNZKNVNUdSRYDzwduTbJFVd2SZAuavTlJksZFv60ir0/yz8Crga36XGbTJH/QPl4PeC5wNXAmcGQ725HAt0ZYsyRJq9XvD7R3BvYG/ifwkSQ7ApdV1UvWsMwWwElJ1qEJ0K9W1VlJLgK+muR1wE3Ay0dfviRJj9ZvsK2gaeq/AngYuJVhDiG2PwnYYxXjlwMHjqxMSZL602+w3QlcDnwU+HwbTpIkTTn9too8HDgfOAb4lyTvT+JelyRpyum3VeS3aHr33xF4AU1z/3cA6w2uNEmSRq7fVpFfT3I98HFgDvBngH08SpKmnH7PsR0H/KS96KgkSVNWv8F2KfCmJM9sh88DPltVDw6kKkmSRqnfYPtHmk6MP9MOv7od9/pBFCVJ0mj1G2x7tZefWelHSS4bREGSJI1Fv839V7S9+wOQZFuaH2tLkjSl9LvH9nbg3CQ3AAG2Bl4zsKokSRqlfn/HtijJ9sAONMF2dVXdP9DKJEkahTUGW5I/Wc2k7ZJQVd8YQE2SJI3acHtsf7yGaQUYbJKkKWWNwVZVnkeTJE0ra2wVmeRVSVY7T5Ltkuw//mVJkjQ6wx2K3Bj4aZJLgEuAZcBs4H8AzwJuBxYOtEJJkkZguEORH0/yKeA5wH7AbsC9wFXAq6vqpsGXKElS/4Zt7t92fHxOe5MkaUrrt+cRSZKmBYNNktQpwwZbkhlJ/nQiipEkaayGDbaqehh48wTUIknSmPV7KPKcJH+dZKskG628DbQySZJGod/e/V/b3r+pZ1wB245vOZIkjU2/vftvM+hCJEkaD30FW5JZwF8Az2xHLQY+V1UPDqguSZJGpd9Dkf8IzAI+0w6/uh33+kEUJUnSaPUbbHtV1dN7hn+U5LJBFCRJ0lj02ypyRZLtVg4k2RZYMZiSJEkavX732P4aODfJDUCArQGv1SZJmnKGDbYk6wBPB7YHdqAJtqur6v4B1yZJ0oj10/PICuDQqrq/qn5WVZcZapKkqarfQ5H/r70u2+nAPStHVtVPBlKVJEmj1G+wPaO9/0DPuKK5AKkkSVNGv+fYzqyqj01APZIkjUnf59gmoBZJksbMc2ySpE7xHJskqVP67d3/gEEXIknSeOirS60kT0ryhSTfa4d3TvK6wZYmSdLI9dtX5JeBHwBPbof/Czh2APVIkjQm/QbbJlX1VeBhgKp6CDtBliRNQf0G2z1JNqZpMEKSfYDfDqwqSZJGqd9WkW8DzgS2S3IhsCnwsoFVJUnSKPXbKvInSZ7F73v3v6aqHhxoZZIkjUK/e2wrz6tdOcBaJEkas37PsUmSNC0YbJKkTlljsCV5Vc/j/YZMe/OgipIkabSG22N7W8/jTw6Z9tpxrkWSpDEbLtiymserGpYkadINF2y1mserGpYkadIN19x/xyQ/o9k72659TDu87UArkyRpFIYLtp0mpApJksbJGoOtqn7RO9z2F/lM4KaqumSQhUmSNBrDNfc/K8mu7eMtgCtoWkN+Jcmxgy9PkqSRGa7xyDZVdUX7+DXAOVX1x8De2NxfkjQFDRdsvR0dHwh8F6Cq7qK9NtvqJNkqyblJrkpyZZK/bMdvlOScJNe2908cyxOQJKnXcMF2c5K3JHkJsCfwfYAk6wGzhln2IeB/VdVOwD7Am5LsDCwEFlXV9sCidliSpHExXLC9DtgFOAp4RVXd0Y7fB/jSmhasqluq6ift47uAq4CnAC8CTmpnOwl48SjqliRplYZrFXkb8MZVjD8XOLffjSSZC+wB/AfwpKq6pV3PLUk2W80yRwNHAzz1qU/td1OSpLXcGoMtyZlrml5Vhw63gSRzgK8Dx1bVnUl/PXFV1YnAiQDz58+3lxNJUl+G+4H2vsDNwGk0e1sj6h8yySyaUPvnqvpGO/rWJFu0e2tbALeNsGZJklZruHNsmwN/A+wKfBw4CLi9qs6rqvPWtGCaXbMvAFdV1Ud7Jp0JHNk+PhL41mgKlyRpVdYYbFW1oqq+X1VH0jQYuQ5YnOQtfax7P+DVwHOSXNreXggcBxyU5FqaoDxubE9BkqTfG+5QJEnWBQ4GDgfmAp8AvrGmZQCq6gJWf+jywP5LlCSpf8M1HjmJ5jDk94D39/RCIknSlDTcHturgXuApwFv7WnRGKCq6gkDrE2SpBEb7ndswzUukSRpSjG4JEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMGFmxJvpjktiRX9IzbKMk5Sa5t7584qO1LktZOg9xj+zLw/CHjFgKLqmp7YFE7LEnSuBlYsFXV+cCvh4x+EXBS+/gk4MWD2r4kae000efYnlRVtwC095utbsYkRydZkmTJsmXLJqxASdL0NmUbj1TViVU1v6rmb7rpppNdjiRpmpjoYLs1yRYA7f1tE7x9SVLHTXSwnQkc2T4+EvjWBG9fktRxg2zufxpwEbBDkqVJXgccBxyU5FrgoHZYkqRxM3NQK66qw1cz6cBBbVOSpCnbeESSpNEw2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTpmUYEvy/CTXJLkuycLJqEGS1E0THmxJ1gE+DbwA2Bk4PMnOE12HJKmbJmOPbQFwXVXdUFUPAP8CvGgS6pAkddDMSdjmU4Cbe4aXAnsPnSnJ0cDR7eDdSa6ZgNrGYhPg9kGsOP8wiLVqmhrY54z3ZyCr1bQ1uO+0o8bts7b1qkZORrCt6hnVY0ZUnQicOPhyxkeSJVU1f7LrULf5OdNEmc6ftck4FLkU2KpneEvgV5NQhySpgyYj2H4MbJ9kmySPAw4DzpyEOiRJHTThhyKr6qEkbwZ+AKwDfLGqrpzoOgZg2hw21bTm50wTZdp+1lL1mNNbkiRNW/Y8IknqFINNktQpBtsoJFmR5NIkVyT5dpI/aMfPTXJvO23l7XGTXK6mgSRbJfl5ko3a4Se2w1sn2T7JWUmuT3JJknOTPLOd76gky9rP2pVJzkiy/uQ+G00nSe5exbj3Jfll+7n6zySHT0Zto2Wwjc69VbV7Ve0K/Bp4U8+069tpK28PTFKNmkaq6mbgH4Hj2lHH0Zy8vxX4DnBiVW1XVX8IvAXYtmfx09vP2i7AA8ArJq5yddjHqmp3mp6hPpdk1iTX07fJ+IF211wE7DbZRagTPgZckuRYYH+aAHs1cFFVPfKTmKq6Arhi6MJJZgIbAL+ZkGq1Vqiqa5P8DngicNtk19MPg20M2g6dDwS+0DN6uySXto8vrKo3PWZBaRWq6sEkbwe+D/xRVT2QZBfgJ8Ms+ook+wNbAP8FfHvApWotkmRP4NqqmhahBh6KHK312vBaDmwEnNMzrfdQpKGmkXoBcAuw66omJvlme273Gz2jT28PGW0OXA68feBVam3wV20fvf8BvG+SaxkRg2107m2/SLYGHsejz7FJo5Jkd+AgYB+aL5UtgCuBPVfOU1UvAY6i+YfqUar5Ueq3gWdOQLnqvo9V1Q4052xPTjJ7sgvql8E2BlX1W+CtwF9PpxOrmnqShKbxyLFVdRNwPPAR4FRgvySH9sy+plaP+wPXD6xQrXWq6hvAEuDIya6lX55jG6Oq+mmSy2j6vPy3ya5H09afAzdV1crD2p+h2TNbABwCfDTJCTStJO8C/q5n2ZXn2GbQdDJ+1MSUrI5YP8nSnuGPrmKeDwCnJvl8VT08QXWNml1qSZI6xUORkqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg00aJ0kqyVd6hme2Pe+f1Q4fleRTE1jPl5O8bKzzSNONwSaNn3uAXZOs1w4fBPxyEuuR1koGmzS+vgcc3D4+HDhtJAsnuTHJh5NclGRJkj2T/KC9Ftsb23mS5Pi2z8jLk7yiZ/yn2utnfQfYrGe9f5jkvPZ6bj9ou+sauu3j2mV/luQjo30BpMlmsEnj61+Aw9p+9Xaj6UB2pG6uqn1perL5MvAymv4jP9BO/xNgd+DpwHOB49ugegmwAzCPpieTZwC03b19EnhZez23LwIf6t1ge4HTlwC7VNVuPLpnE2lasUstaRxV1c+SzKXZW/vuKFez8tprlwNzquou4K4k97VXa98fOK2qVgC3JjkP2Ium8+OV43+V5EftenaguVrAOU2XlKxDcwWBXncC9wH/1O7tnTXK2qVJZ7BJ4+9Mmg6Mnw1sPIrl72/vH+55vHJ4JpA1LLuqPvICXNnuBa56oaqHkiygub7gYcCbgeeMpGhpqvBQpDT+vgh8oKouH9D6z6fp+HidJJvS7Kld3I4/rB2/BXBAO/81wKZJ9oXm0GR7AdNHJJkDbFhV3wWOpTnUKU1L7rFJ46yqlgIfX83ko5K8uGd4n3b+kfgmsC9wGc0e2juq6r+TfJNmL+tymitpn9fW80DbpP8TSTak+bs/geZabys9HvhWe24wwF+NsCZpyrB3f0lSp3goUpLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdcr/B0D1C3DAjETlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# mse error values\n",
    "mse_rf = mean_squared_error(y_test, y_pred_RF)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_XG)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_LR)\n",
    "\n",
    "# Position of bars on x-axis\n",
    "ind = ['RF' , 'XGB' , 'LR']\n",
    "\n",
    "# Figure size\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "# Plotting\n",
    "plt.bar(ind[0], mse_rf , width, label='mse_rf')\n",
    "plt.bar(ind[1], mse_xgb, width, label='mse_xgb')\n",
    "plt.bar(ind[2], mse_lr, width, label='mse_lr')\n",
    "\n",
    "plt.xlabel('ML models')\n",
    "plt.ylabel('MSE error (lower is better)')\n",
    "plt.title('MSE values for three different models')\n",
    "\n",
    "# Show the legend in the graph\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Choosing the best model using hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9099, 11)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X and y arrays for the hypothesis testing\n",
    "X = np.concatenate((X_train, X_test), axis = 0)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9099,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.concatenate((y_train, y_test), axis = 0)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before the test, we will set the significant threshold alpha = 0.05.\n",
    "We will perform a **Paired student's t-test with a 5x2 Cross Validation**. This means that we will use a two-fold CV with five repeats and then use the Paired t-test to test if the performance of the two models is statistically significant or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: The average performance (mean squared error) of the Random Forest model and the XG Boost model are identical.\n",
    "\n",
    "**Alternate hypothesis**: The average performance of the two models are not identical and there is a statistically significant difference in their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance threshold\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = paired_ttest_5x2cv(estimator1=best_randomforest, estimator2=best_xgboost, X=X, y=y, scoring='neg_mean_squared_error', random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.450, t-Statistic: 0.820\n"
     ]
    }
   ],
   "source": [
    "print('P-value: %.3f, t-Statistic: %.3f' % (p, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value is greater than or equal to alpha. Hence, we cannot reject the Null hypothesis\n"
     ]
    }
   ],
   "source": [
    "if p < alpha:\n",
    "    print(\"P-value is less than alpha. Hence, we can reject the Null hypothesis and choose the Alternate hypothesis\")\n",
    "else:\n",
    "    print(\"P-value is greater than or equal to alpha. Hence, we cannot reject the Null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above P-value, it is clear that the mean performance of the two models is most likely similar and we cannot choose one over the other with statistical confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence, both the Random forest and the XG Boost models perform equally well on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
